---
title: "Download data"
author: "steppe"
date: "2023-10-14"
output: html_document
---

```{r load packages}
library(tidyverse)
library(BIEN)
library(ridigbio)
library(rgbif)
library(sf)
source('functions.R')
```

```{r import and clean target species}
targets <- read.csv('../data/raw/2024sos_species.csv', na.strings = "") %>% 
  filter(!species %in% c('tridentata', 'millefolium', 'dioica', 'negundo')) %>%  # purshia,
  unite('taxon', genus:infraspecies, na.rm = T, sep = ' ') %>% # artemisia, and larrea !
  mutate(taxon = str_squish(taxon))

targets %>% 
  group_by(symbol, taxon) %>% 
  count()

target_taxa <- targets %>% 
  pull(taxon) %>% 
  unique() # 293 species. 

target_symbols <- targets %>% 
  pull(symbol) %>% 
  unique()

## we will not model a few species which are widely abundant, hence do not require modelling, and would utilize enormous computational resources.

```

```{r Perform gbif queries, eval = F}
user <- "steppe" # your gbif.org username 
pwd <- "blmquery" # your gbif.org password # this one is now old and serves as an example
email <- "reedbenkendorf27@gmail.com" # your email 

gbif_taxon_keys <- target_taxa[294:364] %>% 
  name_backbone_checklist()  %>% 
  filter(!matchType == "NONE") %>% 
  pull(usageKey)

dl_key <- occ_download(
  pred_in("taxonKey", gbif_taxon_keys),
  user=user, pwd=pwd, email=email,
  pred("country", "US"),
  pred("hasCoordinate", TRUE),
  pred("hasGeospatialIssue", FALSE),
  pred_gte("year", 1900)
)

occ_download_wait(dl_key)
occ_download_get( dl_key )

rm(user, pwd, email, gbif_taxon_keys, dl_key)
```


BIEN is pretty finicky these days and is prone to crashing. There is a paper by Maitner with Enquist, Wilson, Merow etc. about the need for open source devs to be rewarded academically, I take that has a sign of Brian stepping away from it. We will use a for loop to download from BIEN. 
```{r Perform bien queries, eval = F}

for(i in seq_along(target_taxa)){
  print(target_taxa[i])
  dl <- BIEN_occurrence_species(target_taxa[i], collection.info = TRUE, observation.type = TRUE, new.world = TRUE)
  write.csv(dl, file.path('../data/raw/occurrence/bien', paste0(gsub(' ', '_', target_taxa[i]), '.csv')) )#, row.names = FALSE)
}
```

```{r stitch together BIEN queries, eval = F}

p <- '../data/raw/occurrence/bien'
files <- file.path(p, list.files(p))

lapply(Filter(function(x) R.utils::countLines(x)==1, files), unlink) # delete empty CSV's in directory
files <- file.path(p, list.files(p))

bien_data <-  do.call(rbind, lapply(files, read.csv)) %>% 
  filter(datasource != 'GBIF' & date_collected > '1950-01-01', ! scrubbed_species_binomial %in% c('Acer negundo', 'Prosopis glandulosa')) %>% 
  drop_na(date_collected, latitude) %>% 
  select(scrubbed_species_binomial:datasource, observation_type)

write.csv(bien_data, '../data/raw/occurrence/BIEN_records.csv', row.names = FALSE)
```


```{r Perform idigbio queries, eval = F}

ob <- lapply(target_taxa, idig_records)
idig <- bind_rows(ob) %>% 
  filter(datecollected > '1950-01-01')

write.csv(idig, '../data/raw/occurrence/IDIG.csv')

```

```{r Import and Query AIM data, eval = F}

p1 <- '../data/raw/2021_AIM_Terrestrial/AIMTerrestrial9-1-22.gdb'

st_layers(dsn = p1)

AIM_points <- st_read(dsn = p1, 
        layer = 'TerrADat', quiet = T) %>%
  select(PrimaryKey, DateVisited, geometry = Shape) %>% 
  st_transform(5070) 

spp_richness <- st_read(dsn = p1, 
        layer = 'tblSpecRichDetail', quiet = T) %>% 
  select(SpeciesList, PrimaryKey) %>% 
  filter(SpeciesList %in% target_symbols) %>% 
  right_join(AIM_points, by = 'PrimaryKey') %>% 
  st_as_sf()  %>% 
  mutate(DateVisited = as.Date(DateVisited), .before = geometry) %>% 
  arrange(SpeciesList) %>% 
  right_join(., select(targets, taxon, symbol) %>% 
               distinct(), by = c('SpeciesList' = 'symbol' ))

st_write(spp_richness, '../data/raw/occurrence/AIM/AIM_records.shp', append = F)

rm(p1, AIM_points)
```


```{r}
rm(idig_records, target_symbols, target_taxa)
```

```{r Create consensus presence records}

base_p <- '../data/raw/occurrence'

bien <- read.csv(file.path(base_p, 'BIEN_records.csv')) %>% 
  st_as_sf(coords = c('longitude', 'latitude'), crs = 4326) %>% 
  mutate(date = as.Date(date_collected)) %>% 
  select(taxon = scrubbed_species_binomial, date)

idig <- read.csv(file.path(base_p, 'IDIG.csv')) %>% 
  st_as_sf(coords = c('geopoint.lon', 'geopoint.lat'), crs = 4326) %>% 
  mutate(date = as.Date(datecollected)) %>% 
  select(taxon = scientificname, date)

aim <- st_read(file.path(base_p, 'AIM', 'AIM_records.shp'), quiet = TRUE) %>% 
  mutate(date = as.Date(DatVstd)) %>% 
  select(taxon, date, PrmryKy) %>% 
  st_transform(4326)

gbif1 <- read.delim(file.path(base_p, 'gbif1', 'occurrence.txt'), na.strings = "") %>% 
  drop_na(decimalLongitude, decimalLatitude) %>% 
  filter(str_detect(decimalLatitude, '[A-Z]|[a-z]', negate = T)) %>% 
  st_as_sf(coords = c('decimalLongitude', 'decimalLatitude'), crs = 4326) %>% 
  mutate(date = as.Date(eventDate), .before = geometry, 
         coordinateUncertaintyInMeters = as.numeric(coordinateUncertaintyInMeters)) %>% 
  filter(coordinateUncertaintyInMeters <= 250) %>% 
  select(taxon = species, date)
  
gbif2 <- read.delim(file.path(base_p, 'gbif2', 'occurrence.txt'), na.strings = '')%>% 
  drop_na(decimalLongitude, decimalLatitude) %>% 
  filter(str_detect(decimalLatitude, '[A-Z]|[a-z]', negate = T)) %>% 
  st_as_sf(coords = c('decimalLongitude', 'decimalLatitude'), crs = 4326) %>% 
  mutate(date = as.Date(eventDate), .before = geometry, 
         coordinateUncertaintyInMeters = as.numeric(coordinateUncertaintyInMeters)) %>% 
  filter(coordinateUncertaintyInMeters <= 250) %>% 
  select(taxon = species, date)

records <- bind_rows(aim, bien, gbif1, gbif2, idig) %>% 
  mutate(taxon = str_to_sentence(taxon), 
         taxon = str_squish(taxon)) %>% 
  filter(taxon %in% unique(targets$taxon)) %>% 
  arrange(taxon) # recs need be > 90 m from each other

rm(aim, bien, gbif1, gbif2, idig)

splicies <- split(records, records$taxon)

thinned <- lapply(splicies, ONEperCELL)
thinned <- bind_rows(thinned)
st_write(thinned, '../data/raw/occurrence/thinned/thinned_occurrences.shp', append = F)
repeated_occurrences <- lapply(splicies, multiplesPERcell)
repeated_occurrences <- purrr::discard(repeated_occurrences, ~nrow(.) < 2)
repeated_occurrences <- bind_rows(repeated_occurrences)
st_write(repeated_occurrences, '../data/raw/occurrence/repeated/repeated_occurrences.shp', append = F)

rm(ONEperCELL, multiplesPERcell, records, splicies, repeated_occurrences, base_p)
```


```{r remove points outside analytical area}
library(terra)
domain <- rast(nrows = 1, ncols = 1) # create a big empty raster, you can go in through sf too. 
ext(domain) <- c( -125.5, -100, 27,  50) # set the extent
crs(domain) <- "EPSG:4326" # define the projection

domain <- as.polygons(domain) |>  # convert to vector data
  st_as_sf() |> # convert to simple feature
  st_transform(5070) 

thinned <- st_read('../data/raw/occurrence/thinned/thinned_occurrences.shp', quiet = TRUE)
thinned <- thinned[lengths(st_disjoint(thinned, domain)) ==  0, ]
st_write(thinned, '../data/raw/occurrence/thinned/thinned_occurrences.shp', append = FALSE)

repeated_occurrences <- st_read('../data/raw/occurrence/repeated/repeated_occurrences.shp', quiet = TRUE)
repeated_occurrences <- thinned[lengths(st_disjoint(repeated_occurrences, domain)) ==  0, ]
st_write(repeated_occurrences, '../data/raw/occurrence/repeated/repeated_occurrences.shp', append = FALSE)
```

