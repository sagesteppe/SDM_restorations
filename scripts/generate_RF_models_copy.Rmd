---
title: "Generate Random Forest Models"
author: "steppe"
date: "2023-10-14"
output: html_document
---

```{r}
library(tidyverse)
library(terra)
library(sf)
source('functions.R')
```

```{r read in predictors}

p <- '/media/steppe/hdd/Geospatial_data/WesternPlantPredictors2'
paths <- list.dirs(p, recursive = T)
paths <- paths[2:length(paths)]
paths <- paths[! grepl('chelsa$|veg_cover$|soilgrids$|sand$|silt$|clay$|phh2o$|cfvo$|soc$', paths) ]

files <- lapply(paths, function(x){ file.path(x, list.files(x)) })
names(files) <- basename(paths)

layers <- lapply(files, vrt)
layers <- rast(layers)
names(layers) <- basename(paths)

rm(paths, files)
```

```{r read in response data and model}
p <- '../data/raw/occurrence/combined_records'
p2f <- file.path(p, list.files(p, pattern = '.shp$'))
train_dat <- lapply(p2f, sf::st_read, quiet = TRUE)
train_dat <- bind_rows(train_dat) %>% 
  st_transform(crs(layers))

splicies <- split(train_dat, f = train_dat$taxon)

cores <- parallel::detectCores()
lapply(splicies[1], modeller)

```


```{r}
x <- filter(train_dat, taxon==  'Asclepias cryptoceras' )

  species <- sf::st_drop_geometry(x) %>% 
    dplyr::pull(taxon)
  species <- species[1]
  x1 <- terra::extract(layers, x)
  
  x_dat <- cbind(x$Occurrence, x1) %>% 
    dplyr::mutate(Occurrence = as.factor(`x$Occurrence`)) %>% 
    dplyr::select(-ID, -`x$Occurrence`) %>% 
    dplyr::relocate(Occurrence, .before = 1) %>% 
    dplyr::filter(if_all(2:ncol(.), ~ !is.na(.)))
  
  trainIndex <- caret::createDataPartition(x_dat$Occurrence, p = .8, 
                                           list = FALSE, times = 1)
  TRAIN <- x_dat[ trainIndex,]
  TEST  <- x_dat[-trainIndex,]
  
  

  library(caret)
  
TRAIN <- Boruta_var_selector(TRAIN)
  
  
ctrl <- rfeControl(functions = rfFuncs,
                   method = "repeatedcv", repeats = 5)


floor((ncol(TRAIN)-1)*0.1)*10 # upper subset
subsets = c(30, 25, 20, 15, 10)

rfProfile <- rfe(TRAIN[,2:ncol(TRAIN)], TRAIN$Occurrence,
                 sizes = subsets,
                 rfeControl = ctrl)

# accept a percent change with less than -1.5% 
results <- rfProfile[['results']] %>% 
    mutate(pct_change = (Accuracy/lead(Accuracy) - 1) * 100)

predictors(rfProfile)
plot(rfProfile)

v_no <- filter(results, pct_change > -1.5) %>% 
  # identify all selections which performed well relative to maximal model 
  slice_min(Variables, n = 1) %>%  # now identify the one with the fewest variables
  pull(Variables)

rfProfile[["variables"]] %>% 
  filter(Variables == v_no) %>% 
  group_by(var) %>% 
  summarise(imp = mean(Overall)) %>% 
  arrange(-imp) # tri, slope, cfvo_30_60, phh2o_0_5, ngd10

```






```{r summarize results from RF models}

psum <- '../results/summary'
f <- file.path(psum, list.files(psum))

summary <- lapply(f, read.csv)
names(summary) <- gsub('.csv', '',  basename(f))
summary <- data.table::rbindlist(summary, idcol = 'species')

filter(summary, Metric == 'Balanced Accuracy') %>% 
  ggplot(aes(x = Value)) + 
  geom_histogram() +
  geom_density() 

filter(summary, Metric == 'Sensitivity') %>% 
  ggplot(aes(x = Value)) + 
  geom_histogram()
```

