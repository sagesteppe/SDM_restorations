---
title: "Ground Truth Sampling Cells Colorado Plateau"
author: "steppe"
date: "2024-03-31"
output: html_document
---

To determine whether SDM's and hydrological basins can help find native plant populations field tests were conducted on the Northern Colorado Plateau. 


```{r}
library(sf)
library(terra)
set.seed(23)
```

```{r import species data}
p <- '/media/steppe/hdd/2024SOS_CrewGeospatial/Plateau â€“ Senior Botanist/Geodata'
f <- paste0(p, '/Species/SDM/', 
       list.files(paste0(p, '/Species/SDM/'), pattern = '.shp$'))
dat <- lapply(f, st_read, quiet = T) 
dat <- lapply(dat, '[', 2) 
dat <- lapply(dat, terra::vect)
names(dat) <- gsub('.shp$', '', basename(f))
# dat <- bind_rows(dat, .id = 'Taxon')

rm(f)
```


```{r import study extent and convert polygons to rasters, eval = F}

blm_surf <- st_read(paste0(p, '/Admin/Surface/BLM_Surface.shp'), quiet = T) |>
  dplyr::filter(Unit_Nm %in% c('Grand Junction Field Office', 'Uncompahgre Field Office', 'Vernal Field Office', 'Price Field Office'))

r <- rast(blm_surf, resolution = 90, nlyrs = 3) # create 30 meter resolution raster
names(r) <- c('SumOccupiedPatches', 'Sum1stOrderNeighboringPatches', 'CommonessInversion')
datr <- lapply(dat, rasterize, r, field = 'Rank')
datr <- rast(datr)

# count the occupied patches by overlap  
r[[1]] <- app(ifel(datr == 1, 1, NA), sum, na.rm = TRUE)

# count the patches which are first order neighbors from a known-populated locality  
r[[2]] <- app(ifel(datr %in% c(2, 3, 4), 1, NA), sum, na.rm = TRUE)

# How common are occupied + 1st order neighbors for each species? i.e. which are less common
# and should be considered more importantly during scouting ??

datr <- ifel(datr <= 4, 1, NA)
tab <- freq(datr)

tab$InverseWt <- 1 - ( tab$count / max(tab$count))
tab$NegativeInverseWt <- round( 1 / (max(tab$InverseWt+1) - tab$InverseWt), 2) * 100
# extreme skew rescale with 'negative transform', keep digits few for memory.

par(mfrow=c(1,2)) 
hist(tab$InverseWt, main = 'Raw', xlab = 'Weight') 
hist(tab$NegativeInverseWt, main = 'Negative Transform', xlab = 'Weight')  

for (i in seq_along(1:dim(datr)[3])){ 
  datr[[i]] <- ifel(datr[[i]] == 1, tab$NegativeInverseWt[i], NA) 
} 

r[[3]] <- app(datr, sum, na.rm = TRUE)
names(r) <- c('SumOccupiedPatches', 'Sum1stOrderNeighboringPatches', 'SumInverseCommonness')
plot(r)

writeRaster(r, '../results/Summary_Rasters/COPL.tif')

rm(datr, tab, i)
```

```{r mask areas with fewer predicted species}

r <- rast( '../results/Summary_Rasters/COPL.tif')
samples <- spatSample(r, 10000, na.rm = T)

lyr1 <- as.numeric(quantile(samples$SumOccupiedPatches, probs = 0.5))
lyr2 <- as.numeric(quantile(samples$Sum1stOrderNeighboringPatches, probs = 0.5))
lyr3 <- as.numeric(quantile(samples$CommonessInversion, probs = 0.5))

r[[1]] <- ifel(r[[1]] < lyr1, NA, r[[1]])
r[[2]] <- ifel(r[[2]] < lyr2, NA, r[[2]])
r[[3]] <- ifel(r[[3]] < lyr3, NA, r[[3]])

# we will need to sample 2 '1's per species, 3 '2-4's per species. 

rm(lyr1, lyr2, lyr3)
```

```{r reload data to consider each species independently}
datr <- lapply(dat, rasterize, r, field = 'Rank')
datr <- rast(datr)
```

We will consider three attributes of each sampled population... 

```{r draw random points for each species}

samplesFocal <- vector(mode = 'list', length = dim(datr)[3])
samples1stOrder <- vector(mode = 'list', length = dim(datr)[3])

for (i in seq_along(1:dim(datr)[3])){ 
  
  samplesFocal[[i]] <- spatSample(ifel(datr[[i]] == 1, 1, NA), 50, na.rm = TRUE, exhaustive = TRUE, as.points = TRUE)
  samplesFocal[[i]] <- extract(r, samplesFocal[[i]], method = 'bilinear', xy = TRUE)
  samples1stOrder[[i]] <- spatSample(ifel(datr[[i]] %in% c(2, 3, 4), 1, NA), 50, na.rm = TRUE, exhaustive = TRUE, as.points = TRUE)
  samples1stOrder[[i]] <- extract(r, samples1stOrder[[i]], method = 'bilinear', xy = TRUE)
  names(samplesFocal) <- names(datr) ; names(samples1stOrder) <- names(datr)

}

# now we determine which are within X distance of each other... 
ob <- data.frame(
  rbind(
  data.table::rbindlist(samplesFocal, idcol = 'taxon') |>
    dplyr::mutate('Target' = 'Populated'),
  data.table::rbindlist(samples1stOrder, idcol = 'taxon') |>
    dplyr::mutate('Target' = '1stOrder')
)) %>% 
  dplyr::arrange(taxon) %>% 
  sf::st_as_sf(coords = c('x', 'y'), crs = 5070)

ob<- split(ob, f = ob$taxon)

identify_unqiue_pts <- function(x){
  # determine which pairs are unique. 
  DAT <- nngeo::st_nn(x, x, k = 5, maxdist = 2500, sparse = TRUE, returnDist = TRUE)
  names(DAT$nn) <- 1:length(DAT$nn)
  dd <- DAT$nn[ lengths( DAT$nn ) >= 2 ]

  # now we need to remove records which are within this distance from each other... 
  pairs <- vector(mode = 'list', length = length(dd))
  for (i in 1:length(dd)){
    pairs[[i]] <- which ( lapply(dd, setequal, dd[[i]]) == TRUE)
  }

  chosen_pts <- c(
    DAT$nn[ lengths( DAT$nn ) == 1 ],
    DAT$nn[as.numeric(names( unlist(lapply(unique(pairs), sample, 1)) ) )]
  ) |> 
    names() |>
    as.numeric() |>
    sort()

  out <- x[chosen_pts,]
  return(out)
  
}

ob1 <- lapply(ob, identify_unqiue_pts) |>
  bind_rows()
```

Let's determine which sites have useful info

```{r}

obbies <- ob1 %>% 
  rowwise() %>% 
  mutate(sum_na = sum(is.na(c_across(SumOccupiedPatches:CommonessInversion)))) %>% 
  group_by(taxon, Target) %>% 
  arrange(taxon, Target, sum_na, -SumOccupiedPatches, -Sum1stOrderNeighboringPatches, -CommonessInversion) %>% 
  slice_head(n = 3)

```


Create site indexes for all sample points

```{r}

ggplot() + 
  geom_sf(data = obbies) 

disties <- st_nearest_feature(obbies)  
dd <- st_distance(obbies, obbies[disties,], by_element = TRUE) 

p <- '/media/steppe/hdd/2024SOS_CrewGeospatial/species_check_play/'
st_write(obbies, dsn = paste0(p, 'test.shp'))

```

